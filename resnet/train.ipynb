{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import resnet\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 1e-3\n",
    "BATCH_SIZE = 16 #100\n",
    "EPOCHS = 10 #10\n",
    "# define the train and val splits\n",
    "TRAIN_SPLIT = 0.75\n",
    "VAL_SPLIT = 1 - TRAIN_SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LensTrainDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_dir, u_length):\n",
    "        self.img_dir = img_dir\n",
    "        self.sub_dirs = ['no','sphere','vort']\n",
    "        self.img_labels = list(range(len(self.sub_dirs)))\n",
    "        self.u_length = u_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)*self.u_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, \"%s/%s.npy\"%(self.sub_dirs[int(idx/self.u_length)],idx+1-int(idx/self.u_length)*self.u_length))   \n",
    "        image = torch.Tensor(np.load(img_path))\n",
    "        label = self.img_labels[int(idx/self.u_length)]\n",
    "        # if self.transform:\n",
    "        #     image = self.transform(image)\n",
    "        # if self.target_transform:\n",
    "        #     label = self.target_transform(label)\n",
    "        return image, label\n",
    "    \n",
    "class LensTestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_dir, u_length):\n",
    "        self.img_dir = img_dir\n",
    "        self.sub_dirs = ['no','sphere','vort']\n",
    "        self.img_labels = list(range(len(self.sub_dirs)))\n",
    "        self.u_length = u_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)*self.u_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, \"%s/%s.npy\"%(self.sub_dirs[int(idx/self.u_length)],idx+1-int(idx/self.u_length)*self.u_length))    \n",
    "        image = torch.Tensor(np.load(img_path))\n",
    "        label = self.img_labels[int(idx/self.u_length)]\n",
    "        # if self.transform:\n",
    "        #     image = self.transform(image)\n",
    "        # if self.target_transform:\n",
    "        #     label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] initializing the ResNet model...\n",
      "[INFO] training the network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [10,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [11,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [12,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [13,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [14,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [15,0,0] Assertion `t >= 0 && t < n_classes` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/anirudh/Documents/GSoC/DeepLense/resnet/train.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anirudh/Documents/GSoC/DeepLense/resnet/train.ipynb#W3sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m# zero out the gradients, perform the backpropagation step,\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anirudh/Documents/GSoC/DeepLense/resnet/train.ipynb#W3sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39m# and update the weights\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anirudh/Documents/GSoC/DeepLense/resnet/train.ipynb#W3sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m opt\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/anirudh/Documents/GSoC/DeepLense/resnet/train.ipynb#W3sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anirudh/Documents/GSoC/DeepLense/resnet/train.ipynb#W3sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m opt\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anirudh/Documents/GSoC/DeepLense/resnet/train.ipynb#W3sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39m# add the loss to the total training loss so far and\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anirudh/Documents/GSoC/DeepLense/resnet/train.ipynb#W3sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m# calculate the number of correct predictions\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GSoC/DeepLense/env/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GSoC/DeepLense/env/lib/python3.10/site-packages/torch/autograd/__init__.py:259\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    250\u001b[0m inputs \u001b[39m=\u001b[39m (\n\u001b[1;32m    251\u001b[0m     (inputs,)\n\u001b[1;32m    252\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(inputs, (torch\u001b[39m.\u001b[39mTensor, graph\u001b[39m.\u001b[39mGradientEdge))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mtuple\u001b[39m()\n\u001b[1;32m    256\u001b[0m )\n\u001b[1;32m    258\u001b[0m grad_tensors_ \u001b[39m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[39mlen\u001b[39m(tensors))\n\u001b[0;32m--> 259\u001b[0m grad_tensors_ \u001b[39m=\u001b[39m _make_grads(tensors, grad_tensors_, is_grads_batched\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    260\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n",
      "File \u001b[0;32m~/Documents/GSoC/DeepLense/env/lib/python3.10/site-packages/torch/autograd/__init__.py:142\u001b[0m, in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m    136\u001b[0m         msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    137\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mgrad can be implicitly created only for real scalar outputs\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m but got \u001b[39m\u001b[39m{\u001b[39;00mout\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m         )\n\u001b[1;32m    140\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg)\n\u001b[1;32m    141\u001b[0m     new_grads\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 142\u001b[0m         torch\u001b[39m.\u001b[39;49mones_like(out, memory_format\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mpreserve_format)\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    144\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     new_grads\u001b[39m.\u001b[39mappend(\u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = LensTrainDataset('../dataset/train/',10000)\n",
    "test_dataset = LensTestDataset('../dataset/val/',2500)\n",
    "labels_length = len(train_dataset.img_labels)\n",
    "numTrainSamples = int(len(train_dataset) * TRAIN_SPLIT)\n",
    "numValSamples = int(len(train_dataset) * VAL_SPLIT)\n",
    "(train_dataset, val_dataset) = torch.utils.data.random_split(train_dataset,\n",
    "\t[numTrainSamples, numValSamples],\n",
    "\tgenerator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "\n",
    "trainSteps = len(train_dataloader.dataset) // BATCH_SIZE\n",
    "valSteps = len(val_dataloader.dataset) // BATCH_SIZE\n",
    "\n",
    "print(\"[INFO] initializing the ResNet model...\")\n",
    "model = resnet.ResNet50().to(device)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=INIT_LR)\n",
    "lossFn = torch.nn.NLLLoss()\n",
    "\n",
    "H = {\n",
    "\t\"train_loss\": [],\n",
    "\t\"train_acc\": [],\n",
    "\t\"val_loss\": [],\n",
    "\t\"val_acc\": []\n",
    "}\n",
    "# measure how long training is going to take\n",
    "print(\"[INFO] training the network...\")\n",
    "startTime = time.time()\n",
    "for e in range(0, EPOCHS):\n",
    "    # set the model in training mode\n",
    "    model.train()\n",
    "    # initialize the total training and validation loss\n",
    "    totalTrainLoss = 0\n",
    "    totalValLoss = 0\n",
    "    # initialize the number of correct predictions in the training\n",
    "    # and validation step\n",
    "    trainCorrect = 0\n",
    "    valCorrect = 0\n",
    "    # loop over the training set\n",
    "    for (x, y) in train_dataloader:\n",
    "        # perform a forward pass and calculate the training loss\n",
    "        (x, y) = (x.to(device), y.to(device))\n",
    "        pred = model(x)\n",
    "        loss = lossFn(pred, y)\n",
    "        # zero out the gradients, perform the backpropagation step,\n",
    "        # and update the weights\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        # add the loss to the total training loss so far and\n",
    "        # calculate the number of correct predictions\n",
    "        totalTrainLoss += loss\n",
    "        trainCorrect += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    with torch.no_grad():\n",
    "\t\t# set the model in evaluation mode\n",
    "        model.eval()\n",
    "        # loop over the validation set\n",
    "        for (x, y) in val_dataloader:\n",
    "            (x,y) = (x.to(device), y.to(device))\n",
    "            # make the predictions and calculate the validation loss\n",
    "            pred = model(x)\n",
    "            totalValLoss += lossFn(pred, y)\n",
    "            # calculate the number of correct predictions\n",
    "            valCorrect += (pred.argmax(1) == y).type(\n",
    "                torch.float).sum().item()\n",
    "    # calculate the average training and validation loss\n",
    "    avgTrainLoss = totalTrainLoss / trainSteps\n",
    "    avgValLoss = totalValLoss / valSteps\n",
    "    # calculate the training and validation accuracy\n",
    "    trainCorrect = trainCorrect / len(train_dataloader.dataset)\n",
    "    valCorrect = valCorrect / len(val_dataloader.dataset)\n",
    "    # update our training history\n",
    "    H[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
    "    H[\"train_acc\"].append(trainCorrect) \n",
    "    H[\"val_loss\"].append(avgValLoss.cpu().detach().numpy())\n",
    "    H[\"val_acc\"].append(valCorrect)\n",
    "    # print the model training and validation information\n",
    "    print(\"[INFO] EPOCH: {}/{}\".format(e + 1, EPOCHS))\n",
    "    print(\"Train loss: {:.6f}, Train accuracy: {:.4f}\".format(\n",
    "        avgTrainLoss, trainCorrect))\n",
    "    print(\"Val loss: {:.6f}, Val accuracy: {:.4f}\\n\".format(\n",
    "        avgValLoss, valCorrect))\n",
    "\n",
    "# finish measuring how long training took\n",
    "endTime = time.time()\n",
    "print(\"[INFO] total time taken to train the model: {:.2f}s\".format(\n",
    "\tendTime - startTime))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now evaluate the network on the test set\n",
    "print(\"[INFO] evaluating network...\")\n",
    "# turn off autograd for testing evaluation\n",
    "with torch.no_grad():\n",
    "\t# set the model in evaluation mode\n",
    "\tmodel.eval()\n",
    "\t\n",
    "\t# initialize a list to store our predictions\n",
    "\tpreds = []\n",
    "\t# loop over the test set\n",
    "\tfor (x, y) in test_dataloader:\n",
    "\t\tx = x.to(device)\n",
    "\t\t# make the predictions and add them to the list\n",
    "\t\tpred = model(x)\n",
    "\t\tpreds.extend(pred.argmax(axis=1).cpu().numpy())\n",
    "# generate a classification report\n",
    "# print(classification_report(test_dataloader.dataset.targets.cpu().numpy(),\n",
    "# \tnp.array(preds), target_names=test_dataloader.dataset.classes))\n",
    "\n",
    "# plot the training loss and accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(H[\"train_loss\"], label=\"train_loss\")\n",
    "plt.plot(H[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(H[\"train_acc\"], label=\"train_acc\")\n",
    "plt.plot(H[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig('plot.png')\n",
    "# serialize the model to disk\n",
    "torch.save(model, 'model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
