{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import resnet\n",
    "import pytorch_lightning as pl\n",
    "import tqdm\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import copy\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "# device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 1e-4\n",
    "BATCH_SIZE = 15 #100\n",
    "EPOCHS = 10 #10\n",
    "# define the train and val splits\n",
    "TRAIN_SPLIT = 0.75\n",
    "VAL_SPLIT = 1 - TRAIN_SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out_name = \"augrottrans\"\n",
    "classes = ['no','sphere','vort']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LensTrainDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_dir, sub_class_dir, u_length, classes):\n",
    "        self.img_dir = img_dir\n",
    "        self.classes = classes\n",
    "        self.sub_class_dir = sub_class_dir\n",
    "        self.img_labels = list(range(len(self.classes)))\n",
    "        self.u_length = u_length\n",
    "        self.sub_classes = {'rotation':7,'translation':4}\n",
    "        # self.sub_classes = {'translation':4}\n",
    "        self.n_subclasses = 0\n",
    "        self.sub_class_identifier = []\n",
    "        counter = 1\n",
    "        for label in self.sub_classes:\n",
    "            self.n_subclasses += self.sub_classes[label]\n",
    "            self.sub_class_identifier.append(counter+self.sub_classes[label])\n",
    "            counter += self.sub_classes[label]\n",
    "\n",
    "    def __len__(self):\n",
    "        additional_length = 0\n",
    "        for label in self.sub_classes.keys():\n",
    "            additional_length += self.sub_classes[label]*len(self.img_labels)*self.u_length\n",
    "        return len(self.img_labels)*self.u_length+additional_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item_sub_class = idx//(self.u_length*len(self.classes))\n",
    "        \n",
    "        for i in range(len(self.sub_class_identifier)):\n",
    "            if item_sub_class < self.sub_class_identifier[i]:\n",
    "                sub_class_directory = list(self.sub_classes.keys())[i]\n",
    "                break\n",
    "        if item_sub_class == 0: sub_class_directory = 'None'\n",
    "        item_class = (idx - item_sub_class*len(self.classes)*self.u_length)//self.u_length\n",
    "        if item_sub_class == 0:\n",
    "            img_path = os.path.join(self.img_dir, \"%s/%s.npy\"%(self.classes[item_class],(idx%self.u_length)+1))\n",
    "            image = torch.Tensor(np.load(img_path))\n",
    "        else:\n",
    "            img_path = os.path.join(self.sub_class_dir, \"%s/%s/%s_%d.npy\"%(self.classes[item_class],sub_class_directory,(idx%self.u_length)+1,item_sub_class))\n",
    "            img_path = os.path.join(self.img_dir, \"%s/%s.npy\"%(self.classes[item_class],(idx%self.u_length)+1))\n",
    "            try:\n",
    "                image = torch.Tensor(np.array(np.load(img_path)))\n",
    "            except EOFError:\n",
    "                print(img_path)\n",
    "                image = torch.Tensor(np.array([np.load(img_path)]))\n",
    "\n",
    "        label = self.img_labels[item_class]\n",
    "        return image, label\n",
    "    \n",
    "class LensTrainOriginalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_dir, sub_class_dir, u_length, classes):\n",
    "        self.img_dir = img_dir\n",
    "        self.classes = classes\n",
    "        # self.sub_class_dir = sub_class_dir\n",
    "        self.img_labels = list(range(len(self.classes)))\n",
    "        self.u_length = u_length\n",
    "        # self.sub_classes = {'rotation':7}\n",
    "\n",
    "    def __len__(self):\n",
    "        # additional_length = 0\n",
    "        # for label in self.sub_classes.keys():\n",
    "        #     additional_length += self.sub_classes[label]*len(self.img_labels)*self.u_length\n",
    "        return len(self.img_labels)*self.u_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item_sub_class = idx//(self.u_length*len(self.classes))\n",
    "        item_class = (idx - item_sub_class*len(self.classes)*self.u_length)//self.u_length\n",
    "        # if item_sub_class == 0:\n",
    "        img_path = os.path.join(self.img_dir, \"%s/%s.npy\"%(self.classes[item_class],(idx%self.u_length)+1))\n",
    "        image = torch.Tensor(np.load(img_path))\n",
    "        # else:\n",
    "        #     img_path = os.path.join(self.sub_class_dir, \"%s/%s/%s_%d.npy\"%(self.classes[item_class],'rotation',(idx%self.u_length)+1,item_sub_class))\n",
    "        #     img_path = os.path.join(self.img_dir, \"%s/%s.npy\"%(self.classes[item_class],(idx%self.u_length)+1))\n",
    "        #     try:\n",
    "        #         image = torch.Tensor(np.array(np.load(img_path)))\n",
    "        #     except EOFError:\n",
    "        #         print(img_path)\n",
    "        #         image = torch.Tensor(np.array([np.load(img_path)]))\n",
    "\n",
    "        label = self.img_labels[item_class]\n",
    "        return image, label\n",
    "    \n",
    "class LensTestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_dir, u_length, classes):\n",
    "        self.img_dir = img_dir\n",
    "        self.classes = classes\n",
    "        self.img_labels = list(range(len(self.classes)))\n",
    "        self.u_length = u_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)*self.u_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, \"%s/%s.npy\"%(self.classes[int(idx/self.u_length)],idx+1-int(idx/self.u_length)*self.u_length))\n",
    "        image = torch.Tensor(np.load(img_path))\n",
    "        label = self.img_labels[int(idx/self.u_length)]\n",
    "        # if self.transform:\n",
    "        #     image = self.transform(image)\n",
    "        # if self.target_transform:\n",
    "        #     label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetDeepLense(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = resnet.ResNet50(img_channels=1,num_classes=3)\n",
    "        self.loss = torch.nn.CrossEntropyLoss()\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    # @auto_move_data\n",
    "    def training_step(self, batch, batch_no):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss(logits, y)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_no):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss(logits, y)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=INIT_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 270000 samples to train, and 90000 to validate over 10 epochs\n",
      "[INFO] initializing the ResNet model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anirudh/Documents/GSoC/DeepLense/env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "Training epoch 0:   0%|          | 0/1800 [00:05<?, ?batch/s, acc=0.133, loss=1.2]  "
     ]
    }
   ],
   "source": [
    "train_dataset = LensTrainDataset('../dataset/train/', '/media/anirudh/Extreme SSD/DeepLense/augmented_data', 10000, classes)\n",
    "test_dataset = LensTestDataset('../dataset/val/', 2500, classes)\n",
    "labels_length = len(train_dataset.img_labels)\n",
    "\n",
    "numTrainSamples = int(len(train_dataset) * TRAIN_SPLIT)\n",
    "numValSamples = int(len(train_dataset) * VAL_SPLIT)\n",
    "print(\"[INFO] %d samples to train, and %d to validate over %d epochs\"%(numTrainSamples,numValSamples,EPOCHS))\n",
    "(train_dataset, val_dataset) = torch.utils.data.random_split(train_dataset,\n",
    "\t[numTrainSamples, numValSamples])\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=15)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=15)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=15)\n",
    "\n",
    "trainSteps = len(train_dataloader.dataset) // BATCH_SIZE\n",
    "valSteps = len(val_dataloader.dataset) // BATCH_SIZE\n",
    "\n",
    "print(\"[INFO] initializing the ResNet model...\")\n",
    "model = ResNetDeepLense().to(device)\n",
    "# model = lenet.LeNet(1,3).to(device)\n",
    "\n",
    "batches_per_epoch = int(len(train_dataset)/(EPOCHS*BATCH_SIZE))\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(),lr=INIT_LR)\n",
    "best_acc = -np.inf\n",
    "best_weights = None\n",
    "\n",
    "scheduler = ReduceLROnPlateau(opt,'min',patience=2,factor=0.1,verbose=True)\n",
    "history = {'val_loss':[],'val_acc':[]}\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = []\n",
    "    epoch_acc = []\n",
    "    with tqdm.trange(batches_per_epoch, unit=\"batch\", mininterval=0) as bar:\n",
    "        bar.set_description(f\"Training epoch {epoch}\")\n",
    "        model.train()\n",
    "        for (images, labels) in train_dataloader:\n",
    "            (images, labels) = (images.to(device), labels.to(device))\n",
    "            out_images = model(images)\n",
    "            loss = loss_fn(out_images, labels)\n",
    "            acc = (torch.argmax(out_images, 1) == labels).float().mean()\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            bar.set_postfix(\n",
    "                loss=float(loss),\n",
    "                acc=float(acc)\n",
    "            )\n",
    "        model.eval()\n",
    "        bar.set_description(f\"Testing epoch {epoch}\")\n",
    "        for (images, labels) in test_dataloader:\n",
    "            (images, labels) = (images.to(device), labels.to(device))\n",
    "            out_images = model(images)\n",
    "            val_loss = loss_fn(out_images, labels)\n",
    "            acc = (torch.argmax(out_images, 1) == labels).float().mean()\n",
    "            epoch_loss.append(float(val_loss))\n",
    "            epoch_acc.append(float(acc))\n",
    "            bar.set_postfix(\n",
    "                val_loss=float(val_loss),\n",
    "                acc=float(acc)\n",
    "            )\n",
    "    history['val_loss'].append(np.mean(epoch_loss))\n",
    "    history['val_acc'].append(np.mean(epoch_acc))\n",
    "    if np.mean(epoch_acc) > best_acc:\n",
    "        best_acc = np.mean(epoch_acc)\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    "    print(f\"Epoch {epoch} validation: Cross-entropy={np.mean(epoch_loss)}, Accuracy={np.mean(epoch_acc)}, LR={opt.param_groups[0]['lr']}\")\n",
    "    scheduler.step(np.mean(epoch_loss))\n",
    "\n",
    "torch.save(model, 'saved%s.pth'%model_out_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_prediction(x, model: pl.LightningModule):\n",
    "#   model.freeze() # prepares model for predicting\n",
    "#   probabilities = torch.softmax(model(x), dim=1)\n",
    "#   predicted_class = torch.argmax(probabilities, dim=1)\n",
    "#   return predicted_class, probabilities\n",
    "\n",
    "# inference_model = ResNetDeepLense.load_from_checkpoint(\"resnet50_deeplense.pt\", map_location=\"cuda\").to(device)\n",
    "# true_y, pred_y, prob_l = [], [], []\n",
    "# for batch in tqdm(iter(test_dataloader), total=len(test_dataloader)):\n",
    "#   x, y = batch\n",
    "#   (x, y) = (x.to(device), y.to(device))\n",
    "#   true_y.extend(y)\n",
    "#   preds, probs = get_prediction(x, inference_model)\n",
    "#   pred_y.extend(preds)\n",
    "#   prob_l.extend(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# pred_y = torch.Tensor(pred_y)\n",
    "# true_y = torch.tensor(true_y)\n",
    "# print(classification_report(true_y, pred_y, digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
